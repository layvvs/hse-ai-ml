## Выводы по домашнему заданию


В части с EDA мы изучали наши трейн и тест выборки. Были обнаружены проблемы в виде дублей, пропусков, которые в ходе работы были устранены. Была сделана минимальная визуализация данных, чтобы посмотреть на зависимости и примерно оценить их вид. В данных присутствовали числовые, категориальные и текстовые признаки, которые мы обрабатывали при помощи различных методов: категориальные мы кодировали при помощи OHE и Target Encoding с Leave One Out подходом, а текстовые данные пришлось парсить, чтобы оставить только ту информацию, которая представлена в виде чисел. Было интересно собственноручно реализовывать коэффициент корреляции Спирмана и сравнивать его с библиотечной реализацией.

В итоге после EDA и предобработки остались чистые данные, с помощью которых можно обучить модель.

В работе было обучено несколько видов моделей и с разными подходами: где-то мы делали нормализацию данных, а где-то нет, где-то добавляли новые фичи.

При пробации разных подходов я заметил, что наибольший вклад дает именно работа с признаками. Не сильно удалось прочувстовать вклад конкретно скейла данных, так как от этого качество модели у меня не менялось, а вот добавление категориальных фичей + генерация фичей смогли повысить бейзлайновое качество по R2 с 0.53 до 0.73, также рост показали и бизнесовые метрики качества. Изменение самих моделей, увеличение регуляризации также не сильно меняли картину, больший вклад все равно остается за данными.

Не до конца осознал как работает L0 регуляризация, нужно более детально в нее углубиться, но ее предназначение, как я понял, в селекции фичей.

Видно, что даже очень простые модели могут хорошо обобщать данные, если нормально подобрать и обработать признаки.

При выполнении работы мне однозначно не хватало знаний из статистики, чтобы понимать распределение данных и проводить более детальный анализ, поэтому качество моделей могло бы быть еще лучше. Еще бы я побольше поработал с признаками, добавил бы каких-то новых, которые есть в открытом доступе по тем авто, что есть в датасете.

Остались открытые вопросы, которые связаны с весами и с ответами моделей - вроде нет линейных зависимостей в данных, но веса все равно не в одной шкале, а переобучения я не заметил. А в некоторых случаях модель выдавала отрицательные предсказания - тут тоже еще не разобрался. Также иногда метрика на тесте была выше, чем на трейне - тут будто связано с тем, что в тесте есть дубли данных

Итого мы познакомились с тем, как выполнять EDA, подбирать гиперпараметры модели, регуляризацией и стримлитом. Стримлит оказался очень полезным инструментом, который за считанные минуты позволяет создать красивую веб аппу, в которой можно отобразить основные результаты проделанной работы. Конечно в текущем решении есть недочеты, но главное, что я понимаю какие именно и что нужно изучить, чтобы модели стали лучше
